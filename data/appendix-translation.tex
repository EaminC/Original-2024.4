% !TeX root = ../thuthesis-example.tex

\begin{translation}
\label{cha:translation}

\title{GPT4Rec: A Generative Framework for Personalized
Recommendation and User Interests Interpretation}
\maketitle

\tableofcontents

\section{摘要}
近期的研究者在自然语言处理（NLP）方面取得了较大进展，并且将这些技术应用于推荐系统，显示出卓越的性能。然而，目前的模型通常将项目仅视为ID，并采用判别建模，导致以下限制：(1) 无法充分利用项目的内容信息和NLP模型的语言建模能力；(2) 无法解释用户兴趣以提高相关性和多样性；(3) 无法适应项目库存增长等实际情况。为了解决这些限制，我们提出了GPT4Rec，这是一种受搜索引擎启发的新颖且灵活的生成框架。它首先根据用户历史中的项目标题生成假设的“搜索查询”，然后通过搜索这些查询来检索推荐项目。该框架通过在语言空间中学习用户和项目嵌入，克服了先前所提到的限制。为了更好地捕捉用户兴趣的不同方面和精细程度，以提高相关性和多样性，我们提出了一种基于束搜索的多查询生成技术。生成的检索词自然地作为用户兴趣的可解释表示，并且可以通过搜索推荐冷启动项目。本工作中使用GPT-2语言模型和BM25搜索引擎，最终在两个公共数据集上的Recall@K分别比最先进的方法高出75.7\%和22.2\%。实验结果进一步表明，基于束搜索的多查询生成提高了检索项目的多样性和用户多兴趣的覆盖率。最终我们还通过定性案例研究讨论了生成查询的适应性和可解释性。

\section{计算机分类系统概念}
信息系统 → 推荐系统


\section{引言}
推荐系统是信息过滤系统，用于提供个性化的建议，以推荐与特定用户相关的项目，广泛应用于电子商务和社交媒体服务\cite{4, 11, 14, 19}。随着自然语言处理（NLP）的发展，许多基于NLP的模型通过建模用户-项目交互序列来进行个性化推荐\cite{9, 27, 30}。大型语言模型（LLM，\cite{1, 5, 17, 24}）在各种NLP任务或对话（如ChatGPT\cite{16}）中取得了卓越的表现，推动了基于LLM的推荐系统的研究\cite{6, 10, 15, 22, 23, 29}。特别是，BERT4Rec\cite{23}采用了BERT\cite{5}的双向自注意力结构，超越了其他基于NLP的模型和序列模型\cite{9, 10, 18}。

尽管模型性能有所提升，但现有的基于NLP的模型\cite{6, 10, 15, 22, 23, 29}通常将项目仅视为ID并采用判别建模，存在以下限制：首先，这些模型无法充分利用项目的内容信息和NLP模型的语言建模能力。其次，这些模型无法适应不断变化和增长的项目库存，而这些都是重要的实际问题\cite{12, 21}。此外，判别模型难以解释用户兴趣，这对于提高推荐的多样性和质量至关重要\cite{2, 3, 13, 28}。

为了解决这些限制，我们提出了GPT4Rec，这是一种新颖且灵活的生成框架，用于个性化推荐，并同时提供用户兴趣的解释。我们的框架灵感来自搜索引擎：GPT4Rec首先使用生成语言模型生成假设的“搜索查询”，该模型将用户历史中的项目标题与生成提示结合作为输入。然后，GPT4Rec通过搜索生成的查询来检索推荐项目。GPT4Rec的关键组件是一个强大的生成语言模型，它在语言空间中学习用户和项目的嵌入，使我们能够利用项目标题中的语义信息并捕捉用户的多样兴趣。为了解码用户的多重兴趣并提高推荐的多样性，我们在查询生成中采用了多查询束搜索技术。这些查询是人类可理解的，并且在解释用户兴趣方面具有独立价值。此外，通过搜索代表用户兴趣的查询进行推荐，可以自然地解决项目冷启动问题和项目库存变化问题。最后，GPT4Rec在实践中具有灵活性，可以结合更先进的LLM或搜索引擎以提高性能。
\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{figures/GPTREC.png}
    \caption{GPT4Rec框架的架构}
    \label{fig:enter-label}
\end{figure}
总之，我们的贡献包括：（1）我们提出了GPT4Rec，一种新颖且灵活的生成框架，将推荐任务视为查询生成+搜索；（2）我们采用多查询束搜索策略，生成多样且可解释的用户兴趣表示；（3）我们在两个公共数据集上进行了实验，展示了Recall@K相对于最先进方法的显著改进；（4）通过定量和定性分析，我们调查并展示了生成查询的数量提高了检索项目的多样性以及用户多重兴趣的覆盖率。

\section{方法}
我们的框架的架构如图1所示。给定用户的项目交互序列，GPT4Rec通过提示格式化项目标题，并使用生成语言模型在语言空间中学习项目和用户嵌入。然后，该模型生成多个代表用户兴趣的查询，这些查询将被输入到搜索引擎中以检索推荐项目。在本文中，我们选择了GPT-2语言模型和BM25搜索引擎，而该框架可以灵活地结合更先进的模型。

\subsection{使用语言模型进行查询生成}
GPT4Rec的第一个组件是生成语言模型，其目标是从项目交互序列中学习语言空间中的用户表示，然后生成多个代表用户兴趣的查询。通过微调选择的GPT-2模型（该模型具有117M参数，具有复杂的transformer架构，并在庞大的语言语料库上进行了预训练），实现捕捉用户兴趣和项目内容信息的目的。通过实验，我们决定使用以下提示格式化模型输入：
\vspace{1\baselineskip}
\begin{quote}
之前，顾客购买了：\\
<项目标题1>。<项目标题2>...\\
未来，顾客想购买
\end{quote}
\vspace{1\baselineskip}
这个提示包含项目标题中的语义信息，并被记作每个用户的$W_u$。GPT-2从$W_u$学习用户表示，然后能够基于条件分布$P(·|W_u)$以序列方式生成查询。

为了更好地表示用户的多样兴趣并增加推荐结果的多样性，我们建议使用束搜索技术生成多个查询\cite{18, 25}。给定束宽$m$，生成评分函数$S(·)$，以及长度为$l$的候选查询$Q_l = (q_{l1}, q_{l2}, ..., q_{lm})$，束搜索算法将$Q_{l+1}$更新为长度为$l + 1$的前$m$个查询，这些查询最大化$S(W_u, q)$，其中$q \in \{|q| = l + 1, q[1:l] \in Q_l\}$。最重要的是，这种束搜索策略生成了在不同方面和粒度上多样化的用户兴趣表示。

\subsection{使用搜索引擎进行项目检索}
我们框架的第二个组件是一个搜索引擎，它作为“判别器”使用。它将每个生成的查询作为输入，并使用匹配评分函数从库存中检索最相关的项目。匹配评分函数测量语言空间中的相似性，发挥类似于向量嵌入方法中的内积相似性的作用\cite{4, 19}。我们选择采用BM25匹配评分函数\cite{20}，因为它是最广泛使用的基准搜索引擎之一，考虑了词频饱和和文档长度，具有两个相应的参数$k_1$和$b$。

其中$K$表示推荐项目的总数，$m$表示生成的查询数量，我们提出一种基于排名的策略来结合每个查询的搜索结果。首先使用生成评分最高的查询从搜索结果中检索前$K/m$个项目，然后按分数排名依次添加其余查询中$K/m$个不重复的项目。所提出的策略能够平衡检索项目的相关性和多样性。

\subsection{训练策略}
我们提出了一种灵活的两步训练过程，分别优化语言模型和搜索引擎，这在模型迭代中非常有利。给定每个用户$u$的项目交互序列$i_1, i_2, ..., i_T$，我们在2.1节所示的提示中取前$T-1$个项目标题，然后将其与最后一个项目$i_T$的标题连接起来，形成训练语料库，以微调预训练的GPT-2模型。这种策略受到对比学习文献\cite{8}的启发，其基本思想是最细粒度和最准确的搜索查询是目标项目标题本身。在训练完语言模型后，我们通过网格搜索参数$k_1$和$b$优化BM25参数，以在搜索生成查询以检索目标项目时获得最佳性能。

\section{实验}
\subsection{实验设置}
\subsubsection{数据}
我们在两个公共数据集上进行实验，分别是5-core Amazon Review数据集\cite{7}中的美容和电子产品类别。标题缺失或噪声标题（超过400个字符）的项目被丢弃。每个用户的项目交互序列去重并截取到最大长度为15。预处理数据集的描述性统计如表2所示。按照下一项预测任务设置\cite{23}，用户序列按0.8/0.1/0.1的比例分割为训练集、验证集和测试集，并将每个测试序列中的最后一项视为预测目标。
\vspace{1\baselineskip}
\begin{table}[ht]
\tiny
\centering
\caption{基线方法和提出框架的整体性能，生成不同数量查询的情况下。最佳性能以粗体显示，最佳基线结果下划线标记。}
\begin{tabular}{lcccccccccc}
\hline
Dataset & Recall@K & FM-BPR & ContentRec & YouTubeDNN & BERT4Rec & \multicolumn{4}{c}{GPT4Rec} \\

 &  &  &  &  & & 5 Queries & 10 Queries & 20 Queries & 40 Queries \\
\hline
Beauty & K=5 & 0.0356 & 0.0254 & \underline{0.0376} & 0.0355 & \textbf{0.0653} & -- & -- & -- \\
 & K=10 & 0.0499 & 0.0440 & 0.0549 & 0.0513 & 0.0810 & \textbf{0.1036} & -- & -- \\
 & K=20 & 0.0716 & 0.0644 & 0.0753 & 0.0816 & 0.1207 & 0.1252 & \textbf{0.1454} & -- \\
 & K=40 & 0.1040 & 0.0952 & 0.1066 & 0.1161 & 0.1297 & 0.1522 & 0.1743 & \textbf{0.2000} \\
\hline
Electronics & K=5 & 0.0345 & 0.0241 & 0.0352 & \underline{0.0362} & 0.0434 & \textbf{0.0545} & -- & -- \\
 & K=10 & 0.0387 & 0.0307 & 0.0435 & \underline{0.0451} & 0.0480 & \textbf{0.0515} & -- & -- \\
 & K=20 & 0.0441 & 0.0391 & 0.0539 & 0.0573 & 0.0524 & 0.0607 & \textbf{0.0705} & -- \\
 & K=40 & 0.0505 & 0.0494 & 0.0684 & 0.0751 & 0.0574 & 0.0672 & 0.0788 & \textbf{0.0918} \\
\hline
\end{tabular}
\end{table}

\vspace{1\baselineskip}

\begin{table}[ht]
\centering
\caption{数据集统计信息}
\small
\begin{tabular}{lccccccc}
\hline
Name & User & Item & Interaction & Ave. Length & Meta Info. \\
\hline
Beauty & 22,254 & 11,778 & 190,726 & 7.439 & Cate. \\
Electronics & 728,719 & 159,456 & 6,724,582 & 7.297 & Cate., Brand \\
\hline
\end{tabular}
\end{table}

\vspace{1\baselineskip}
\newpage
\subsubsection{评估指标}
Recall@K是预测下一项的主要兴趣指标，衡量推荐的前K项中是否包含目标项，并在所有用户中取平均值。除了Recall@K，我们还对以下指标感兴趣：

\vspace{1\baselineskip}
\textbf{Diversity@K}衡量项目之间的差异性，定义如下：
\vspace{1\baselineskip}
\begin{equation}
\text{Diversity@K} = \text{Average} \left[ 1 - \frac{\sum_{i_1 \neq i_2} \text{Sim}(i_1, i_2)}{K(K-1)} \right]
\end{equation}
其中采用Jaccard相似度\cite{1}来测量项目类别或品牌之间的相似性。
\vspace{1\baselineskip}

\textbf{Coverage@K}衡量推荐项目的覆盖范围，定义如下：
\vspace{1\baselineskip}
\begin{equation}
\text{Coverage@K} = \text{Average} \left[ \frac{|\bigcup_{i \in R} \text{Cate}(i) \cap \bigcup_{i \in U} \text{Cate}(i)|}{|\bigcup_{i \in U} \text{Cate}(i)|} \right]
\end{equation}
这是一种更合理的度量用户多重兴趣覆盖率的方法，与Diversity@K完全不同\cite{2}。
\vspace{1\baselineskip}
\subsubsection{基线方法}
FM-BPR\cite{11}是一种使用贝叶斯个性化排序标准的因子分解机器，学习用户-项目交互矩阵的协同信息。ContentRec是一种基于内容的模型，广泛应用于行业，学习项目标题的词嵌入，并将这些嵌入应用于用户交互项的词嵌入。YouTubeDNN\cite{4}是行业中最流行的深度学习模型之一，采用网络来学习用户-项目嵌入。BERT4Rec\cite{23}是一种最先进的BERT模型，具有双向自注意力架构和掩码训练策略。

\subsubsection{实现细节}
我们实现了GPT-2模型，由HuggingFace提供\cite{26}，具有117M参数，并通过Adam优化器和学习率衰减进行微调。我们将学习率设置为0.0001并使用2000步预热。BM25通过网格搜索$k1 \in [0, 3]$，$b \in [0,1]$优化。ContentRec由StarSpace\cite{27}实现。所有基线方法在公共GitHub库\cite{3}上可用。对于基线方法，我们选择了最佳维度641,128,256基于原论文作者的意见。

\section{定量分析}
\subsection{总体性能}
表1总结了GPT4Rec在两个数据集上不同生成查询数的Recall@K与基线方法的比较。我们的框架在两个数据集上都优于所有基线方法，在较小的美容数据集上实现了75.7\%的相对改进，在较大的电子产品数据集上实现了Recall@K@40上的22.2\%的改进。

与基线方法的比较表明，项目信息和现代语言建模是实现卓越性能的关键因素。一方面，BERT4Rec在两种数据集上表现最好，但由于将项目视为ID而未能充分利用项目的内容信息。另一方面，ContentRec的词嵌入和多项式建模不足以实现可比性能。

\subsection{多查询生成的优势}
表1和表3中的数据表明，随着生成查询数的增加，推荐结果的相关性和多样性显著提高。特别是，生成多查询的束搜索策略显著提高了推荐的相关性。生成K个查询并检索每个查询的前K项项目获得了最佳的Recall@K性能。表3中的Diversity@K和Coverage@K的增加趋势也证明了多查询生成策略能够产生更综合的用户兴趣表示。

进一步调查生成查询的多样性和用户兴趣的覆盖率表明，多查询生成策略能捕捉用户更广泛的兴趣。相反，增加查询数量而不生成多样性则无法提高性能。

这些结果表明，多查询生成在提高推荐多样性和相关性方面具有显著优势。我们的框架灵活地结合了更先进的生成语言模型和搜索引擎，提供了进一步探索的有趣方向。

\begin{table}[ht]
\centering
\caption{用户兴趣的多样性和覆盖率与生成查询数量的对比。关于类别/品牌信息的最高值以粗体显示。}
\tiny % 控制表格字体大小
\begin{tabular}{lccccccccccccc}
\hline
Dataset & \multicolumn{4}{c}{Beauty (Category)} & \multicolumn{4}{c}{Electronics (Category)} & \multicolumn{4}{c}{Electronics (Brand)} \\
\hline
Number of Queries & & 5 & 10 & 20 & 40 & 5 & 10 & 20 & 40 & 5 & 10 & 20 & 40 \\
\hline
Diversity@K & K=5 & \textbf{0.679} & -- & -- & -- & \textbf{0.671} & -- & -- & \textbf{0.534} & -- & -- & -- \\
 & K=10 & 0.654 & \textbf{0.716} & -- & -- & 0.617 & \textbf{0.733} & -- & -- & 0.529 & \textbf{0.643} & -- & -- \\
 & K=20 & 0.659 & 0.706 & \textbf{0.749} & -- & 0.605 & 0.703 & \textbf{0.778} & -- & 0.559 & 0.645 & \textbf{0.717} & -- \\
 & K=40 & 0.679 & 0.715 & 0.749 & \textbf{0.783} & 0.601 & 0.696 & 0.762 & \textbf{0.811} & 0.604 & 0.669 & 0.724 & \textbf{0.767} \\
\hline
Coverage@K & K=5 & \textbf{0.417} & -- & -- & -- & \textbf{0.321} & -- & -- & \textbf{0.173} & -- & -- & -- \\
 & K=10 & 0.472 & \textbf{0.547} & -- & -- & 0.340 & \textbf{0.425} & -- & -- & 0.177 & \textbf{0.239} & -- & -- \\
 & K=20 & 0.535 & 0.602 & \textbf{0.674} & -- & 0.364 & 0.447 & \textbf{0.537} & -- & 0.184 & 0.245 & \textbf{0.317} & -- \\
 & K=40 & 0.614 & 0.669 & 0.726 & \textbf{0.787} & 0.389 & 0.474 & 0.562 & \textbf{0.653} & 0.197 & 0.255 & 0.324 & \textbf{0.403} \\
\hline
\end{tabular}
\end{table}


\begin{figure}[htbp]
    \centering
    \begin{minipage}[t]{0.42\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{figures/11.png}
        \caption{具有多样兴趣的美容产品测试用户示例，目标项目以红色圈出。}
        \label{fig:beauty-example}
    \end{minipage}
    \hspace{0.05\linewidth}
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics[width=1\linewidth]{figures/22.png}
        \caption{具有具体兴趣的电子产品测试用户示例，目标项目以红色圈出。}
        \label{fig:electronics-example}
    \end{minipage}
\end{figure}


\subsection{定性分析}
在本节中，我们探讨了生成查询在捕捉用户兴趣和解释用户兴趣方面的有效性，并通过案例研究展示了其用处。我们在图2和图3中展示了两个测试用户序列和模型输出。

在第一个例子中，测试用户对美容产品的多个类别和品牌有多样的兴趣。在这种情况下，GPT4Rec能够生成不仅覆盖用户历史中的一些产品或品牌的多样查询，还生成用户历史中从未出现的相关项目，例如“化妆盘”。这表明GPT4Rec能够基于用户-项目交互和项目标题语义信息，捕捉项目之间的关联性。在第二个例子中，测试用户对罗技无线鼠标有非常具体的兴趣。GPT4Rec能够捕捉这一特征，所有生成的查询都集中在同一个品牌上，相同类别但产品细节不同。

我们已经证明了GPT4Rec在生成捕捉用户兴趣的查询方面的有效性，这些查询跨越了不同的方面和粒度水平，如上面两个案例研究所示。这些查询直接为解释用户兴趣服务。此外，两个例子的比较表明，生成查询的多样性水平适应了用户序列中的水平，这有助于进一步了解他们的行为。

\section{结论}
在这项工作中，我们提出了GPT4Rec，一个新颖的生成框架，可以同时生成个性化推荐和可解释的用户兴趣表示。利用先进的语言模型和项目内容信息，GPT4Rec实现了卓越的性能，并自然地解决了项目冷启动问题。所提出的多查询束搜索技术生成了在不同方面和粒度上多样的用户兴趣表示，提高了推荐结果的相关性和多样性。我们的框架具有灵活性，可以结合更先进的生成语言模型或搜索引擎，以及更好的生成和检索策略，这些都是未来探索的有趣方向。




\newpage

% 书面翻译的参考文献
\bibliographystyle{unsrtnat}
\bibliography{ref/appendix}

% 书面翻译对应的原文索引
\begin{translation-index}
  \nocite{salomon1995advanced}
  \bibliographystyle{unsrtnat}
  \bibliography{ref/appendix}
\end{translation-index}

\end{translation}
