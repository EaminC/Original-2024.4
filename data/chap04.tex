% !TeX root = ../thuthesis-example.tex
\chapter{实验}
\section{实验设置}


\subsection{数据集}

为了验证推荐系统的推荐效果，本实验需要一个同时包含有用户信息
物品文本信息以及用户与物品交互信息的真实数据集。基于此本工作选择了MovieLens数据集\cite{harper2015movielens}。该数据集由GroupLens组织\cite{grouplens}在电影推荐平台上收集的用户对电影的真实评分数据。自发布至今涵盖了接近20年的时间跨度,同时发布了100K、1M、10M及20M \cite{movielens_100k,movielens_1m,movielens_10m,movielens_20m}.等不同数据规模的数据集。出于运算成本以及特征提取难度的考量,本实验主要采用的数据集是MovieLens-1M数据集。本工作当前使用数据集为离线数据集，同时电影数据集所包含的字段是上一章节所提到的完整物品数据集的子集，在当前阶段数据已经足以验证框架的合理性。本工作后续迭代版本将基于真实生产环境中的在线实时数据以及完整的数据结构进行在线版本的开发测试。


MovieLens-1M 数据集是从 MovieLens 网站收集而来，包含了 6,040 名用户对 3,883 部电影的 1,000,209 条评分记录。每位用户至少为 20 部电影进行了评分。该数据集涵盖了多种类型的电影，并且用户的评分分布在时间上较为均匀。本研究利用 MovieLens-1M 数据集来评估推荐系统的性能。

在本工作中，将数据集分为训练集、验证集和测试集，比例为 8:1:1，以用于基于模型的推荐系统训练。数据集中还包括用户的基本信息（如年龄、性别、职业）和电影的基本信息（如标题、类型）。

此外，为了处理评分数据，本工作对评分的时间戳进行了预处理，转换为年、月、日等格式，从而能够在后续时间尺度上对模型进行处理时能够更加方便的处理数据。同时加入对用户信息转换为完整句子的接口方便后续进行语义分析。

关于数据集的一些其他统计学特性在如下表格中体现:

\begin{table}[h!]
\centering
\caption{MovieLens-1M 数据集的统计特性}
\begin{tabular}{@{}l r@{}}
\toprule
统计量 & 数值 \\
\midrule
用户数 &   6,040 \\
电影数 &  3,883 \\
评分数 & 1,000,209 \\
用户平均评分数 &  165.5 \\
电影平均评分数 &  257.6 \\
平均评分 & 3.58 \\
\bottomrule
\end{tabular}

\label{table:movielens_1m_stats}
\end{table}


\subsection{评价指标}

在本节中将介绍本工作中所使用的推荐系统的评价指标，具体而言，对于最后的推荐系统需要量化评价准确率以及质量，从而使用Recall@k和NDCG@k\cite{herlocker2004evaluating,jarvelin2002cumulated}作为评价指标，分别评价排序召回率及排序质量。本节将介绍本工作中使用的这两个指标以及具体计算方法。
 
先前章节对于推荐问题进行了一些抽象建模，与先前符号相同，在推荐系统中给定用户集合 $\mathcal{U} = \{u_1, u_2, \cdots, u_m\}$ 和一个项目集合 $\mathcal{I} = \{i_1, i_2, \cdots, i_n\}$，交互状态空间可以表示为一个矩阵 $R \in \mathbb{R}^{m \times n}$，其中 $R_{ui}$ 表示用户 $u$ 对项目 $i$ 的评分。如果用户 $u$ 没有对项目 $i$ 评分，则 $R_{ui}$ 为缺失值。推荐系统目标为根据用户在前一部分项目上的评分数据 $\{I_1, I_2, \cdots, I_{n-k}\}$，预测用户在后一部分项目上的评分 $\{I_{n-k+1}, \cdots, I_n\}$。即，利用前 $n-k$ 个项目的评分记录来预测剩余项目的评分，由推荐系统给出预测值 $\{I'_{n-k+1}, \cdots, I'_n\}$ 与真实值 $\{I_{n-k+1}, \cdots, I_n\}$ 进行比较。\\
 \textbf{Recall@k} 召回率用于衡量推荐列表与真实交互记录的重合度，仅衡量推荐的准确率而不反映推荐质量。度量范围为0到1，数值越高则重合度越高，参数k衡量度量范围。
\begin{equation}
\text{Recall@k} = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} \frac{| \{I_{n-k+1}, I_{n-k+2}, \ldots, I_n\} \cap \{I'_{1}, I'_{2}, \ldots, I'_k\} |}{| \{I_{n-k+1}, I_{n-k+2}, \ldots, I_n\} |}
\end{equation}      
\textbf{NDCG （Normalized Discounted Cumulative Gain）} 归一化折损累计增益用于计算召回结果的推荐质量，若用户高评价物品排序更考前，则可以得到更高的分数。度量范围为0到1，数值越高则推荐质量越高，参数k衡量度量范围。
 
1. DCG@k（Discounted Cumulative Gain）：
\begin{equation}
   \text{DCG@k} = \sum_{i=1}^k \frac{2^{R_{u, I'_{i}}} - 1}{\log_2(i + 1)}
\end{equation} 

2. IDCG@k（Ideal DCG）：
\begin{equation}
   \text{IDCG@k} = \sum_{i=1}^k \frac{2^{R_{u, I_{i}^*}} - 1}{\log_2(i + 1)}
\end{equation} 

3. NDCG@k： 
\begin{equation}
   \text{NDCG@k} = \frac{1}{|\mathcal{U}|} \sum_{u \in \mathcal{U}} \frac{\text{DCG@k}}{\text{IDCG@k}}
\end{equation} 

其中， $R_{u, I'_{i}}$ 是用户 $u$ 对推荐项目 $I'_{i}$ 的评分，$I'_{i}$ 表示推荐系统生成的第 $i$ 个推荐项目，$I_{i}^*$ 表示按真实评分排序的第 $i$ 个项目。


\section{实验内容}
\subsection{基于交互的长短期兴趣变化识别及自适应推荐系统实现}

基于3.2.3中所提及的基于线性权重层的长短期自适应推荐系统网络以及算法3.3中的训练方式，对K取1，2，3，4时的模型分别进行训练，其中K=1的就是原始MF算法的模型作为基线，经过训练后得到MF@Kfold\_agent\_free模型。随后对训练好的模型接入大语言模型记忆体进行模型调用的推断，得到最终的MF@Kfold\_agent模型，并在MovieLens-1M的最后600名用户组成的验证集上进行验证，得到的结果如下图所示：
\begin{table}[h!]
\caption{K-fold MF实验结果}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{@{}l l l l l@{}}
\toprule
Experiment & Recall@1 & Recall@5 & Recall@20 & Recall@100 \\
\midrule
MF@1fold(baseline) & 0.00522 & 0.02642 & 0.09155 & 0.25371 \\
\midrule
MF@2fold\_agent\_free & 0.00466 & 0.02621 & 0.08443 & 0.26017 \\
MF@2fold\_agent & 0.00631 (+20.88\%) & 0.03345 (+26.63\%) & 0.10639 (+16.19\%) & 0.29908 (+17.88\%) \\
\midrule
MF@3fold\_agent\_free & 0.00510 & 0.02617 & 0.09087 & 0.25734 \\
MF@3fold\_agent & 0.00489 (-6.31\%) & 0.02878 (+8.93\%) & 0.09788 (+6.92\%) & 0.27161 (+7.05\%) \\
\midrule
MF@4fold\_agent\_free & 0.00477 & 0.02596 & 0.09040 & 0.26133 \\
MF@4fold\_agent & 0.00518 (-0.77\%) & 0.02766 (+4.69\%) & 0.09702 (+5.98\%) & 0.27142 (+6.98\%) \\
\bottomrule
\end{tabular}
}
\label{table:recall_results}
\end{table}


从实验结果中可以推断出的结论：\\
\textbf{引入量化注意力范围对召回率的改善} \ 通过实验结果可以看出，在K=2，3，4时，相比与基线模型，召回率都有了显著的提升。由于Recall@1的召回条件较为苛刻，存在性能下降以外，其他召回规模都得到了显著的提升。提升最大出现在MF@2fold\_agent模型，在原始基线模型的基础上得到了26.63\%的性能提升。\\
\textbf{改变K值对长期预测的影响} \ 通过横向对比不同基础模型的结果可以看到高注意力范围大致是总交互时长一半时，对于性能提升是最为显著的。但是随着K值增大，高注意力范围逐渐缩短，因而模型一方面在模型中提取的特征减少，另一方面注意力时长简短，导致长期预测性能逐渐降低。\\
\textbf{大语言模型对于语义理解的增强} \ 在各组实验中，相比与没有大语言模型接入的量化模型而言，由大语言模型进行语义推理以及模型调度的模型都有性能上的提升，因此可以证明大语言模型出色的用户偏好理解能力以及模型调度能力。

其中性能最好的MF@2fold\_agent模型在最常用的召回5个物品的情景之下的累计召回率变化如下图所示：
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{421.png}
    \caption{MF@2fold\_agent Recall@5 实验结果}
    \label{fig:enter-label}
\end{figure}

\subsection{基于语义理解的内容推荐系统实现}

基于3.2.4中的系统设计以及算法3.5的设计，本节实现了基于向量化进行检索的检索系统。接口方面，测试了三种向量化模型或软件库：Bert、TF-IDF及Spacy库，并基于大语言模型对用户未来检索词进行预测，最后使用检索词基于向量化接口进行物品召回。由于检索词较多，需要多组召回，因此最小的@k使用了10作为参数。最终得到的实验结果如下图所示：
\begin{table}[h!]
\centering
\begin{tabular}{@{}lcccccccc@{}}
\toprule
  & \multicolumn{4}{c}{NDCG@k} & \multicolumn{4}{c}{Recall@k} \\
\cmidrule(r){2-5} \cmidrule(l){6-9}
 & k=10 & k=20 & k=50 & k=100 & k=10 & k=20 & k=50 & k=100 \\
\midrule
Bert & 0.1695 & 0.2215 & 0.2789 & 0.3305 & 0.0034 & 0.0073 & 0.0171 & 0.0341 \\
TF-IDF & 0.2151 & 0.2489 & 0.3007 & 0.3541 & 0.0046 & 0.0080 & 0.0184 & 0.0416 \\
Spacy & 0.1912 & 0.2324 & 0.3017 & 0.3380 & 0.0044 & 0.0082 & 0.0206 & 0.0361 \\
\bottomrule
\end{tabular}
\caption{基于不同向量化方法的Query-Search推荐系统性能}
\label{table:recommendation_performance}
\end{table}

基于实验结果，选取性能更好的TF-IDF以及Spacy库进行后续实验。由于Bert性能较差且在后续实验中由于显存占用过大与其他模型无法兼容，因此后续实验基于算力以及性能的考虑不会使用Bert，而是用其余的向量化方法验证框架的性能。

\subsection{基于大语言模型的混合意图识别推荐系统实现}

在本节中基于3.2.5中所设计的混合意图识别推荐系统框架以及算法3.8进行算法实现。在本实验中，作为基线的是多臂老虎机算法（Multi-Armed Bandit, MAB）用于探索行为规律以及探索发掘之间的平衡。并且使用Epsilon-Greedy进行探索从而实现已有信息和新信息的平衡\cite{Sutton1998}，最大化累积奖励\cite{Lattimore2020, Auer2002}，在本工作中进行探索性发掘的概率值设置为0.1.
\vspace{1\baselineskip}
\begin{table}[h!]
\caption{推荐系统性能比较}
\centering
\renewcommand{\arraystretch}{1.2} % Adjust the row height
\setlength{\tabcolsep}{2pt} % Adjust the space between columns
\fontsize{6}{8}\selectfont % Adjust the font size
\begin{tabular}{@{}llcccccccc@{}}
\toprule
 &  & \multicolumn{4}{c}{NDCG@k} & \multicolumn{4}{c}{Recall@k} \\
\cmidrule(r){3-6} \cmidrule(l){7-10}
 & & k=10 & k=20 & k=50 & k=100 & k=10 & k=20 & k=50 & k=100 \\
\midrule
MAB & & 0.1101 & 0.1120 & 0.1245 & 0.1428 & 0.0206 & 0.0373 & 0.0784 & 0.1293 \\
\midrule
 & - & 0.1912 (+73.59\%) & 0.2324 (+107.14\%) & 0.3017 (+142.29\%) & 0.3380 (+136.73\%) & 0.0044 (-78.64\%) & 0.0082 (-78.00\%) & 0.0206 (-73.72\%) & 0.0361 (-72.08\%) \\
 & K1\_align & 0.2435 (+121.06\%) & 0.2514 (+124.52\%) & 0.3019 (+142.49\%) & 0.3461 (+142.43\%) & 0.0042 (-79.61\%) & 0.0061 (-83.65\%) & 0.0142 (-81.89\%) & 0.0291 (-77.49\%) \\
Spacy & K2\_align & 0.1937 (+75.88\%) & 0.2387 (+113.19\%) & 0.2834 (+127.59\%) & 0.3304 (+131.38\%) & 0.0028 (-86.41\%) & 0.0057 (-84.73\%) & 0.0138 (-82.40\%) & 0.0286 (-77.87\%) \\
 & K3\_align & 0.1820 (+65.04\%) & 0.2060 (+83.93\%) & 0.2626 (+110.85\%) & 0.3221 (+125.56\%) & 0.0033 (-83.98\%) & 0.0055 (-85.27\%) & 0.0124 (-84.18\%) & 0.0272 (-78.95\%) \\
 & K4\_align & 0.1759 (+59.76\%) & 0.2057 (+83.71\%) & 0.2609 (+109.54\%) & 0.3202 (+124.21\%) & 0.0033 (-83.98\%) & 0.0058 (-84.47\%) & 0.0126 (-83.93\%) & 0.0265 (-79.49\%) \\
\midrule
 & - & 0.2151 (+95.23\%) & 0.2489 (+122.23\%) & 0.3007 (+141.48\%) & 0.3541 (+148.02\%) & 0.0046 (-77.67\%) & 0.0080 (-78.56\%) & 0.0184 (-76.55\%) & 0.0416 (-67.76\%) \\
 & K1\_align & 0.2190 (+98.19\%) & 0.2482 (+121.61\%) & 0.3019 (+142.49\%) & 0.3343 (+134.14\%) & 0.0039 (-81.07\%) & 0.0066 (-82.30\%) & 0.0150 (-80.87\%) & 0.0279 (-78.43\%) \\
TF-IDF & K2\_align & 0.1927 (+75.03\%) & 0.2265 (+102.24\%) & 0.2729 (+119.17\%) & 0.3281 (+129.91\%) & 0.0031 (-84.95\%) & 0.0056 (-84.98\%) & 0.0126 (-83.93\%) & 0.0274 (-78.80\%) \\
 & K3\_align & 0.1538 (+39.68\%) & 0.1985 (+77.23\%) & 0.2520 (+102.39\%) & 0.3110 (+117.86\%) & 0.0022 (-89.32\%) & 0.0047 (-87.40\%) & 0.0113 (-85.60\%) & 0.0245 (-81.04\%) \\
 & K4\_align & 0.1530 (+38.87\%) & 0.2020 (+80.36\%) & 0.2543 (+104.21\%) & 0.3134 (+119.45\%) & 0.0024 (-88.35\%) & 0.0049 (-86.86\%) & 0.0114 (-85.46\%) & 0.0248 (-80.83\%) \\
\bottomrule
\end{tabular}
\label{table:recommendation_performance}
\end{table}

从实验结果来看，虽然在召回率上相比原先的基线模型性能有所下降，但在召回质量上均有较大的提升，说明模型在提升推荐效果上是有较为优秀的效果的。

\section{实验结论}
在本节中进行了第三章中所设计的基于大语言模型的基于交互行为的长短期自适应推荐网络、基于
正则匹配阈值修正的基于内容推荐网络，以及使用 Query-Search 及行为内容对齐
修正的推荐系统框架的实验验证，最终在自适应长短期推荐模块中提高了至多26.63\%的召回率表现并在最终的整体框架上相比已有的混合框架提升了整体功能性以及框架对混合意图的识别能力，证明框架的有效性。